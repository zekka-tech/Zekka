# Zekka Framework Environment Variables
# Copy this file to .env and fill in your actual values

# ============================================
# REQUIRED: GitHub Integration
# ============================================
# Get your token from: https://github.com/settings/tokens
# Required permissions: repo, workflow, write:packages
GITHUB_TOKEN=ghp_your_github_personal_access_token_here

# ============================================
# MODEL CONFIGURATION - NEW ARCHITECTURE
# ============================================
# Zekka uses different models for different components:
# - Arbitrator: Claude Sonnet 4.5 (conflict resolution)
# - Orchestrator: Gemini Pro (workflow coordination)
# - Fallback: Ollama (all components)

# Arbitrator Model (Conflict Resolution)
# Default: claude-sonnet-4-5 (superior reasoning for code conflicts)
# Requires ANTHROPIC_API_KEY to be set
ARBITRATOR_MODEL=claude-sonnet-4-5

# Orchestrator Model (Workflow Coordination)
# Default: gemini-pro (cost-effective, fast, good quality)
# Requires GEMINI_API_KEY to be set
ORCHESTRATOR_MODEL=gemini-pro

# Fallback Model (Used when primary models are unavailable)
# Default: llama3.1:8b (local Ollama model)
# Always available, no API key needed
FALLBACK_MODEL=llama3.1:8b

# ============================================
# GOOGLE GEMINI API (Orchestrator Primary)
# ============================================
# Get your API key from: https://makersuite.google.com/app/apikey
# See GEMINI_SETUP.md for detailed setup instructions
GEMINI_API_KEY=AIzaSy_your_gemini_api_key_here

# Gemini Model Selection
# Options: gemini-pro, gemini-pro-vision, gemini-1.5-pro
GEMINI_MODEL=gemini-pro

# Gemini Performance Tuning
GEMINI_TEMPERATURE=0.7              # 0.0-1.0 (lower = more deterministic)
GEMINI_MAX_OUTPUT_TOKENS=8192       # Max tokens per response
GEMINI_TOP_P=0.95                   # Nucleus sampling parameter
GEMINI_TOP_K=40                     # Top-k sampling parameter

# Gemini Safety Settings
# Options: BLOCK_NONE, BLOCK_ONLY_HIGH, BLOCK_MEDIUM_AND_ABOVE, BLOCK_LOW_AND_ABOVE
GEMINI_SAFETY_HARASSMENT=BLOCK_MEDIUM_AND_ABOVE
GEMINI_SAFETY_HATE_SPEECH=BLOCK_MEDIUM_AND_ABOVE
GEMINI_SAFETY_SEXUALLY_EXPLICIT=BLOCK_MEDIUM_AND_ABOVE
GEMINI_SAFETY_DANGEROUS=BLOCK_MEDIUM_AND_ABOVE

# ============================================
# OLLAMA (Local LLM - Universal Fallback)
# ============================================
# Ollama is the fallback for ALL components when:
# - Primary model API unavailable
# - Budget limits exceeded
# - Network issues occur
# - Rate limits reached
# - API keys not configured

OLLAMA_HOST=http://ollama:11434

# Ollama Model Selection
# This is the model used when primary models fail
OLLAMA_MODEL=llama3.1:8b           # Default fallback model
# Alternatives: mistral, codellama, gemma:7b, llama3:70b

# ============================================
# LLM STRATEGY (LEGACY - For backward compatibility)
# ============================================
# NOTE: The new architecture uses component-specific models:
# - ARBITRATOR_MODEL for conflict resolution
# - ORCHESTRATOR_MODEL for workflow coordination
# These legacy settings may still be used by older code

# Primary LLM (first choice) - DEPRECATED
PRIMARY_LLM=gemini                  # Options: gemini, ollama, anthropic, openai

# Fallback LLM (used when primary fails or budget exceeded) - DEPRECATED
FALLBACK_LLM=ollama                 # Options: ollama, anthropic, openai, none

# Auto-switch to fallback at % of budget
FALLBACK_THRESHOLD=80               # Switch to fallback at 80% budget

# ============================================
# ANTHROPIC CLAUDE API (Arbitrator Primary)
# ============================================
# Claude Sonnet 4.5 is used by the Arbitrator for conflict resolution
# Get from: https://console.anthropic.com/
# REQUIRED for Arbitrator to use Claude (will fallback to Ollama if not set)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Claude Model Selection
# Options: claude-sonnet-4-5-20250929, claude-opus-4-5-20251101, claude-3-haiku-20240307
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929

# ============================================
# OPTIONAL: OpenAI API
# ============================================
# OpenAI API (can be used for specific tasks via token economics)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview

# ============================================
# Budget Controls (USD)
# ============================================
# Daily spending limit
DAILY_BUDGET=50

# Monthly spending limit
MONTHLY_BUDGET=1000

# Per-project budget cap
PROJECT_BUDGET_CAP=10

# Warning threshold (% of budget)
BUDGET_WARNING_THRESHOLD=75         # Alert at 75% budget used

# ============================================
# Security
# ============================================
# GitHub webhook signature verification
# Generate: openssl rand -hex 32
WEBHOOK_SECRET=your-secure-webhook-secret-here

# JWT secret for authentication (if enabled)
# Generate: openssl rand -base64 32
JWT_SECRET=your-jwt-secret-here

# Session secret
SESSION_SECRET=your-session-secret-here

# API rate limiting
ENABLE_RATE_LIMITING=true
RATE_LIMIT_WINDOW_MS=900000         # 15 minutes
RATE_LIMIT_MAX_REQUESTS=100         # Max requests per window

# ============================================
# Database Configuration
# ============================================
# PostgreSQL (managed by Docker Compose)
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=zekka
POSTGRES_USER=zekka
POSTGRES_PASSWORD=zekka_password_2024

# Connection pool settings
POSTGRES_POOL_MIN=2
POSTGRES_POOL_MAX=10

# ============================================
# Redis Configuration
# ============================================
# Redis Context Bus (managed by Docker Compose)
REDIS_HOST=redis
REDIS_PORT=6379

# Redis connection settings
REDIS_PASSWORD=
REDIS_DB=0
REDIS_KEY_PREFIX=zekka:

# ============================================
# Logging Configuration
# ============================================
# Log level: silly, debug, verbose, info, warn, error
LOG_LEVEL=info

# Log file location
LOG_FILE=./logs/zekka.log

# Log rotation
LOG_MAX_SIZE=10m                    # Max log file size
LOG_MAX_FILES=7                     # Max number of log files

# Enable JSON logging
LOG_JSON=false

# ============================================
# Application Configuration
# ============================================
# Node environment
NODE_ENV=production                 # development, production, test

# Server ports
ORCHESTRATOR_PORT=3000
ARBITRATOR_PORT=3001

# Maximum concurrent agents
MAX_CONCURRENT_AGENTS=50

# Agent timeout (milliseconds)
AGENT_TIMEOUT=300000                # 5 minutes

# Project execution timeout (milliseconds)
PROJECT_TIMEOUT=1800000             # 30 minutes

# ============================================
# Feature Flags
# ============================================
# Enable WebSocket support
ENABLE_WEBSOCKET=true

# Enable Prometheus metrics
ENABLE_PROMETHEUS=true

# Enable API authentication
ENABLE_AUTH=false

# Enable GitHub webhook integration
ENABLE_GITHUB_WEBHOOKS=true

# Enable automatic code formatting
ENABLE_AUTO_FORMAT=true

# ============================================
# Performance Tuning
# ============================================
# Request body size limit
BODY_SIZE_LIMIT=10mb

# File upload size limit
UPLOAD_SIZE_LIMIT=50mb

# Response compression
ENABLE_COMPRESSION=true

# CORS settings
CORS_ORIGIN=*                       # Or specific origin: http://localhost:3000

# ============================================
# Monitoring & Observability
# ============================================
# Prometheus metrics endpoint
PROMETHEUS_PORT=9090
PROMETHEUS_PATH=/metrics

# Health check interval (seconds)
HEALTH_CHECK_INTERVAL=30

# ============================================
# Development Settings
# ============================================
# Enable debug mode (verbose logging, no minification)
DEBUG_MODE=false

# Enable hot reload (development only)
HOT_RELOAD=false

# Mock external APIs (for testing)
MOCK_APIS=false

# ============================================
# Advanced Settings
# ============================================
# GitHub API rate limit
GITHUB_API_RATE_LIMIT=5000

# Retry configuration
MAX_RETRIES=3
RETRY_DELAY_MS=1000

# Cache TTL (seconds)
CACHE_TTL=3600

# Context window sizes per model
CONTEXT_WINDOW_GEMINI=32768
CONTEXT_WINDOW_CLAUDE=200000
CONTEXT_WINDOW_GPT4=128000
CONTEXT_WINDOW_OLLAMA=8192

# ============================================
# Email Configuration
# ============================================
# Email notifications and password reset
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_SECURE=false
SMTP_USER=your-email@gmail.com
SMTP_PASSWORD=your-app-password
SMTP_FROM_EMAIL=noreply@zekka.com
APP_URL=http://localhost:3000
PASSWORD_RESET_EXPIRY_HOURS=1

# Slack notifications
# ENABLE_SLACK_NOTIFICATIONS=false
# SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# ============================================
# Notes
# ============================================
# 1. Never commit this file with real values
# 2. Use strong, unique passwords
# 3. Rotate API keys regularly
# 4. Monitor your usage and costs
# 5. See GEMINI_SETUP.md for Gemini configuration
# 6. See SECURITY.md for security best practices
