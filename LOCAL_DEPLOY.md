# üöÄ Zekka Framework - Local Deployment Guide

## ‚úÖ Status: Ready for Deployment

Your Zekka Framework is now:
- ‚úÖ Uploaded to GitHub: https://github.com/zekka-tech/Zekka
- ‚úÖ Configured with your GitHub token
- ‚úÖ Ready to deploy on your local Docker system

---

## üìã Prerequisites Check

Before running the deployment, ensure you have:

```bash
# Check Docker
docker --version
# Should show: Docker version 20.x or higher

# Check Docker Compose
docker-compose --version
# Should show: Docker Compose version 2.x or higher

# Verify Docker is running
docker ps
# Should not show errors
```

---

## üöÄ Quick Deploy (3 Steps)

### Step 1: Download the Code

```bash
# Clone from GitHub
git clone https://github.com/zekka-tech/Zekka.git
cd Zekka

# Or if you already have it locally at /home/user/webapp/zekka-framework
cd /path/to/zekka-framework
```

### Step 2: Verify Environment

The `.env` file is already configured with your GitHub token. You can optionally add:

```bash
# Edit .env to add optional API keys
nano .env   # or code .env, or vim .env

# Add these if you have them (optional):
ANTHROPIC_API_KEY=sk-ant-your_key_here  # For better AI arbitration
OPENAI_API_KEY=sk-your_key_here         # For GPT models
```

### Step 3: Deploy!

```bash
# Run the setup script
chmod +x setup.sh
./setup.sh
```

**What happens:**
- ‚è≥ Downloads and starts 5 Docker containers
- ‚è≥ Initializes PostgreSQL database
- ‚è≥ Sets up Redis (Context Bus)
- ‚è≥ Downloads AI models (llama3.1, mistral, codellama) - ~5-10 minutes
- ‚è≥ Starts Orchestrator and Arbitrator services
- ‚úÖ Opens dashboard at http://localhost:3000

---

## üñ•Ô∏è Accessing Your System

Once deployment completes:

### **Web Dashboard**
```
http://localhost:3000
```

### **API Endpoints**
```
http://localhost:3000/api          # Main API
http://localhost:3000/health       # Health check
http://localhost:3001              # Arbitrator service
```

### **Service Ports**
- **3000:** Orchestrator (Main app + Dashboard)
- **3001:** Arbitrator (Conflict resolution)
- **5432:** PostgreSQL (Database)
- **6379:** Redis (Context Bus)
- **11434:** Ollama (Local AI models)

---

## üéØ First Project

After the dashboard loads:

1. **Click "Create New Project"**
2. **Fill in:**
   - Name: `My First App`
   - Requirements: `Create a simple todo app with React frontend and Node.js backend`
   - Story Points: `5`
   - Daily Budget: `$10`
3. **Click "Start Project"**
4. **Watch the magic happen!** ‚ú®

**Expected:**
- 50+ AI agents collaborate
- 10 workflow stages execute
- Code generated and reviewed
- Tests written and run
- Complete in ~8-10 minutes

---

## üìä Monitoring

### View Logs
```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f orchestrator
docker-compose logs -f arbitrator
docker-compose logs -f ollama
```

### Check Service Status
```bash
docker-compose ps
```

### Check Resource Usage
```bash
docker stats
```

---

## üõ†Ô∏è Common Commands

### Stop Services
```bash
docker-compose down
```

### Restart Services
```bash
docker-compose restart
```

### Restart Specific Service
```bash
docker-compose restart orchestrator
```

### Full Reset (Removes all data!)
```bash
docker-compose down -v
./setup.sh
```

### Update Code from GitHub
```bash
git pull origin main
docker-compose restart
```

---

## üêõ Troubleshooting

### Port Already in Use
```bash
# Find process using port 3000
lsof -i :3000  # macOS/Linux
netstat -ano | findstr :3000  # Windows

# Stop the process or change ports in docker-compose.yml
```

### Ollama Models Not Downloading
```bash
# Manual download
docker-compose exec ollama ollama pull llama3.1:8b
docker-compose exec ollama ollama pull mistral
docker-compose exec ollama ollama pull codellama
```

### Services Not Starting
```bash
# Check logs
docker-compose logs orchestrator
docker-compose logs postgres

# Restart
docker-compose restart
```

### Database Connection Failed
```bash
# Recreate database
docker-compose down -v
docker-compose up -d postgres
sleep 10
docker-compose up -d
```

---

## üí° Adding Optional AI APIs

To enhance the system with premium AI models:

### 1. Get Anthropic Claude API Key
- Visit: https://console.anthropic.com/settings/keys
- Create new key
- Copy key (starts with `sk-ant-`)

### 2. Add to .env
```bash
nano .env
# Add line:
ANTHROPIC_API_KEY=sk-ant-your_actual_key_here
```

### 3. Restart Services
```bash
docker-compose restart orchestrator arbitrator
```

**Benefits:**
- 92% conflict auto-resolution (vs ~80% with Ollama)
- Better code quality
- Faster decision making

---

## üìà System Requirements

### Minimum (Development)
- **CPU:** 4 cores
- **RAM:** 8GB
- **Storage:** 20GB
- **Network:** 10 Mbps (for model downloads)

### Recommended (Production)
- **CPU:** 8+ cores
- **RAM:** 16GB
- **Storage:** 50GB SSD
- **Network:** 50+ Mbps

### Heavy Load (50+ agents)
- **CPU:** 12+ cores
- **RAM:** 24GB+
- **Storage:** 100GB+ SSD
- **Network:** 100+ Mbps

---

## üí∞ Cost Estimates

### With Ollama Only (Default)
- **Infrastructure:** Free (local)
- **AI Costs:** $0 (local models)
- **Total:** **$0/month** üéâ

### Hybrid (Ollama + Claude)
- **Infrastructure:** Free (local)
- **AI Costs:** $5-20/month (Claude API)
- **Total:** **$5-20/month**

### All Premium (Claude + GPT)
- **Infrastructure:** Free (local)
- **AI Costs:** $20-50/month
- **Total:** **$20-50/month**

**Pro Tip:** System auto-switches to Ollama at 80% budget to prevent overages! üõ°Ô∏è

---

## üîê Security Notes

### GitHub Token Security
- ‚úÖ Token is in `.env` (not committed to Git)
- ‚úÖ `.gitignore` prevents accidental commit
- ‚ùå Never share your `.env` file
- ‚ùå Never commit tokens to public repos

### Production Deployment
When deploying to servers:
- Change `POSTGRES_PASSWORD` to strong password
- Use secrets management (Vault, Docker Secrets)
- Enable HTTPS/TLS
- Set up firewall rules
- Use VPN for admin access

---

## üìö Next Steps

1. ‚úÖ **Deploy Locally:** Run `./setup.sh`
2. ‚úÖ **Create First Project:** Use the dashboard
3. ‚úÖ **Monitor Progress:** Watch the agents work
4. üìñ **Read Documentation:** See README.md for details
5. üöÄ **Deploy to Production:** See DEPLOYMENT.md for cloud options

---

## üÜò Getting Help

### Documentation Files
- `README.md` - Complete system overview
- `QUICK_START.md` - Beginner guide
- `DEPLOYMENT.md` - Production deployment
- `DEPLOYMENT_OPTIONS.md` - All deployment methods

### Check Status
```bash
# System health
curl http://localhost:3000/health

# Database
docker-compose exec postgres pg_isready

# Redis
docker-compose exec redis redis-cli ping

# Ollama
curl http://localhost:11434/api/tags
```

---

## ‚ú® Success Indicators

Your deployment is successful when:
- ‚úÖ Dashboard loads at http://localhost:3000
- ‚úÖ All 5 services show "Up" in `docker-compose ps`
- ‚úÖ Health check returns `{"status":"healthy"}`
- ‚úÖ You can create and run projects
- ‚úÖ Agents execute tasks
- ‚úÖ Real-time metrics display

---

## üéâ You're Ready!

Run this command to start:

```bash
cd /path/to/zekka-framework
./setup.sh
```

Then open: **http://localhost:3000**

**Good luck building with 50+ AI agents! üöÄ**

---

**GitHub Repository:** https://github.com/zekka-tech/Zekka
**Last Updated:** January 2026
**Version:** 1.0.0
